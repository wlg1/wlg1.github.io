I"¶<<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p><strong>CHAPTER 1.1</strong></p>

<p><a href="index.md">back</a></p>

<p>(Reading time: 5 minutes)</p>

<p>Let‚Äôs start with an example that will show us how matrix multiplication transforms data to reveal new insights. Say there‚Äôs a population of cats and rats, and we represent them in a dataset. However, the dataset is only able to measure two features: body size, and face length (or more specifically, snout length).</p>

<p><img src="/cob/fig1.PNG" alt="Figure 1: Cat" />
<!--- middle overlays shapes on top of actual cat. label bottom right as 'data sample'---></p>

<p>So every entity (a cat or rat) in the population is represented in the dataset as an data sample, which is an abstraction defined only by body size and face length, such that their values are measured in ‚Äúunits‚Äù. We can represent the data samples in this dataset as points in a coordinate space, using the two features as axes. The figure below shows the dataset on the left, and its coordinate space representation on the right. The top part shows the data points using numbers, and the bottom part shows how each data point corresponds to a data sample:</p>

<p><img src="/cob/fig2.PNG" alt="Figure 2" />
<img src="/cob/fig3.PNG" alt="Figure 3" />
<!---Make dataset image: first row is face, second row is body, third row is data pt (combo of both) using #s, then show in coord sys on right. Then in 2nd image, turn all numbers into imgs, and again show in coordsys on right.---></p>

<p>Let‚Äôs look at our coordinate space with only the images of unit 1:
<!--- ![Figure 4](/cob/fig4.PNG) --->
<img src="/cob/fig4.png" width="800" height="500" /></p>

<p>Every data point is a combination of the ‚Äúunit 1‚Äù points, which represent <img src="/cob/face1.PNG" width="50" height="40" /> and <img src="/cob/body1.PNG" width="50" height="40" />. For instance, the data point (0.5, 2), which represents <img src="/cob/cat.PNG" width="50" height="40" />, is a weighted combination of 0.5 * <img src="/cob/face1.PNG" width="50" height="40" /> and 2* <img src="/cob/body1.PNG" width="50" height="40" /></p>

<p><img src="/cob/fig5.PNG" alt="Figure 5: Linear Combination" /></p>

<p>If we see each data point as a vector, then every vector such as <img src="/cob/cat.PNG" width="50" height="40" /> is an addition of <img src="/cob/face1.PNG" width="50" height="40" /> and <img src="/cob/body1.PNG" width="50" height="40" />, which are <strong>basis vectors</strong>. Thus (0.5, 2) can also be represented as \(\begin{bmatrix} 0.5 \\ 2 \end{bmatrix} = 0.5 \begin{bmatrix} 1 \\ 0 \end{bmatrix} + 2 \begin{bmatrix} 0 \\ 1 \end{bmatrix}\)</p>

<p><img src="/cob/fig6.PNG" alt="Figure 6: Cat in Coordinate Space" />
<!---
[under each body size pic, number it so reader knows if it's 1, 2, etc. The 2 glues two 1s together, showing the border, the 0.5 shows the other half grayed out, etc. This is to indicate they're scaling the unit vector. But [cat pic] does not do this, since it's not always measured using bodysize or face length, it's just pure data that can be represented using different features. you can show the addition with an 'intermediate step' that shows gluing them on, then removing the borders/faded. can also be gif]---></p>

<hr />

<p>Now there is another way we can measure the data samples in this population. We will no longer label each data sample by the face &amp; body measurements. Instead, we assign each data sample the following two labels:</p>

<p>1) How likely it is to be a cat</p>

<p>2) How likely it is to be a rat</p>

<p>How do we find the values of these new measurements? We can calculate them using the measurements from the previous measurements, face &amp; body. For example:</p>

<p>Shorter face + Bigger body = Cat</p>

<p>Longer face + Smaller body = Rat</p>

<p>Or in terms of basis vector addition:</p>

<p>Fig 7
[figure showing the analogy: 
Bigger body + Shorter face = Likely a Cat
2 * [body pic X] + 0.5 * [face pic Y] = value 2X+0.5Y on cat axes ]</p>

<p>[X and Y are on the row of the matrix corresponding to ‚Äòlikely a cat‚Äô. They are the x values of body1 and face1‚Äôs new coords in Model 2 ]</p>

<p>What are X and Y? These are how much each feature is weighted by to calculate the score of ‚Äúlikely to be cat‚Äù. The higher the weight, the more that feature is taken into account for during calculation. We will reveal how these weights are related to the matrix once we get into the algebra of matrix multiplication in section [].</p>

<p>Note that because this second set of measurements uses different basis vectors, it forms a second coordinate space. Since each coordinate space is a different way to represent the data, let‚Äôs call each coordinate space a Model. The first model we saw will be Model 1, and the second will be Model 2. Since these two measurement methods are measuring the same data samples, the data samples in Model 1 are present in Model 2, but are now measured (in other words, labeled) by different vectors (WHY?- discuss meaning of vector here):
<!---
[coordinate space and labeled vectors don't change, and there's only 1. Only objs prev on basis vectors move.]
[as it's changing, the old basis labels shift too. the word 'body size' shifts into a non-axes vector, but the word 'likely a cat' shifts onto the basis vector. all 4 axes concepts are present.]
[ Another way to fade is to first show images, then fade away into colored dots, then move dots, and fade images back in.]
https://docs.manim.community/en/stable/reference/manim.animation.fading.FadeOut.html
Or fade out still image using video editor---></p>

<!---
ANIMATION: [coordinate space of body size vs face length, showing cat and rat, but onto it fades 'likely a cat' and 'likely a rat'. then it shifts.]--->

<p><img src="/cob/fig8.PNG" alt="Figure 8" /></p>

<p>(Likely a cat 1 (axis j) means ‚Äú1 unit sure‚Äù? Use pic of actual cat with ‚Äòlikely‚Äô over it?)</p>

<p>The <img src="/cob/face1.PNG" width="50" height="40" /> that \(\color{#FA8072}{\begin{bmatrix} 1 \\ 0 \end{bmatrix}}\) pointed to is now in a new location in Model 2. So is the <img src="/cob/body1.PNG" width="50" height="40" /> that \(\color{#CCCCFF}{\begin{bmatrix} 0 \\ 1 \end{bmatrix}}\) pointed to.
<!---* note that [body size 1] is present in Model 2, even though it's missing [face length]. In other words, it's [body size 1] + 0 * [face length 1]. This means that any data point which only contains a body of size 1 is seen as [meaning in terms of basis jk]---></p>

<p>The vector [1 0] used to mean [face 1], but when the features are ‚Äúlikely a cat‚Äù, [1 0] means ‚Äúlikely a cat 1‚Äù, which is different from‚Ä¶</p>

<p>Fig 9a,9b
[Model 1, and Model 1 on top of Model 2. Sys 2 ‚Äòjk‚Äô. WITH vectors.]</p>

<p>Disclaimer: now show with rotated vectors. Animation doesn‚Äôt rotate vectors. This can get confusing because before, the vectors stayed in place. So we have to note that these are different vectors, just colored the same way because they point onto the same data point.
To prev clutter here, ONLY use 2 vectors: c and d. Or perhaps don‚Äôt show them as vectors, just as dots. This should be clean and summarized.</p>

<p>We know in Model 1 that \(\begin{bmatrix} 0.5 \\ 2 \end{bmatrix}\) is <img src="/cob/cat.PNG" width="50" height="40" />. But does this vector point to the same data sample in Model 2?</p>

<p><img src="/cob/fig10.PNG" alt="Figure 10" />
<!---
<img src="/cob/fig10a.png" width="300" height="200">
<img src="/cob/fig10b.png" width="300" height="200">
---></p>

<!---
[[2 0.5] catpic in Model 1 and [2 0.5] in Model 1 on 2. I vector is fixed. unlike prev anim, fade j,k only after change basis so not too cluttered]
[labels cat pic on left, and nothing on right] [color code or include pic of vector when referring to [2 0.5] in text paragraph]
--->
<p>The two \(\color{#CBC3E3}{\begin{bmatrix} 0.5 \\ 2 \end{bmatrix}}\) in each Model do not label the same data point! This is because \(\begin{bmatrix} 0.5 \\ 2 \end{bmatrix}\) no longer has the same meaning in Model 2 as it did in Model 1.</p>

<p>The <strong>meaning</strong> of a vector depends on its basis vectors. Recall that in Model 1, \(\begin{bmatrix} 0.5 \\ 2 \end{bmatrix}\) meant ‚Äúan entity with a short face (0.5) and a long body (2).‚Äù In Model 2, this vector means ‚Äúit‚Äôs not as likely to be a cat (0.5), but more likely to be a rat (2)‚Äù.</p>

<!---
In fact, $$\begin{bmatrix} 0.5 \\ 2 \end{bmatrix}$$ should now point to [rat pic], instead of <img src="/cob/cat.PNG" width="50" height="40">.

Apply inv of matrix onto [0.5, 2] to get rat pic in Model 1, which you use to construct body and face sizes

1 1.5
-1.5 1

0.30769230769230769231  -0.46153846153846153845
0.46153846153846153846  0.3076923076923076923

You get:
1   -0.76923076923076927
2   0.84615384615384618

DO THIS LATER- this is b/c this is a bad matrix to use for classif rat/cat based on body/face (used b/c rotation more intuitive. The good matrix to use is less intuitive.)

Fig ??
[now fill in what [2 0.5] is in Sys 2]
--->

<p>This shows the difference between the data samples in the real world, and the model that represents those data samples using labels. \(\begin{bmatrix} 0.5 \\ 2 \end{bmatrix}\) is not <img src="/cob/cat.PNG" width="50" height="40" /> itself; it is merely a label of it, and whichever label is used depends on the basis vectors used to define the parts of each label.</p>

<p>\(\begin{bmatrix} 0.5 \\ 2 \end{bmatrix} \neq\) <img src="/cob/cat.PNG" width="50" height="40" /></p>

<p>Fig 11
[animated reality of concepts vs fixed coord space model]</p>

<p>Notice that Model 2 demonstrates an idealized, simplified example of what a neural network does- it is making a guess about the data point given to it as input. In fact, one can think of it as a single layer ‚Äòneural network‚Äô such that for its neuron function:</p>

<p>o = ReLU(WX + b)</p>

<p>used to calculate the values it guesses for the 2 classes {cat, rat}, it sets ReLU = identity and b = 0, thus using the equation:</p>

<p>o = WX</p>

<p>Fig 12
[picture of X as input vector, W as arrow, O=WX as Model 2 vector on [cat pic]]</p>

<!---
Fig 13
[fading gif of changing abstractions back to actual pics; place images on coord sys]--->

<p>? * FOOTNOTE: While [cat pic] is merely how the dataset sees [actual cat pic], we are referring to [cat pic] as an ‚Äúentity in the real world‚Äù. This is because the only information the neural network knows about [actual cat pic] comes from [cat pic]. For the purposes of this example, we can replace [cat pic] with [actual cat pic] to explain the same concept. In this example, [cat pic] contains information from the original dataset that does not change after the transformation- namely, body size and face length. However, in other cases, it is possible for a transformation to reduce the information previously contained, although this information may not be important.</p>

<hr />

<p>Let‚Äôs look at another example involving [poison pic and gift pic] to further illustrate the difference between the real world and our coordinate space model. Instead of using numbers, let‚Äôs use letters to label our entities.</p>

<p>[first show coordinate space labeling gift as poison]</p>

<p>To an English speaker, this may look wrong. But in German, [poison pic] is in fact called ‚Äògift‚Äô. If a German speaker tells the English speaker that they‚Äôre giving the English speaker a gift, the English speaker may be delighted. But they shouldn‚Äôt be, because what they‚Äôre actually receiving is [poison pic], which would kill them.</p>

<p>Instead, the English speaker needs to know what [poison pic] is actually referring to. So they need to translate from German to English as follows:</p>

<p>[animation transforming poison and gift pics to English coordinate space. The vector does not move. Label first Sys as German, second as English.]
[Don‚Äôt give names to basis vectors, ONLY show I -&gt; gift, which is wrong.]</p>

<p>label (‚Äògift‚Äô) in German != label (‚Äògift‚Äô) in English
label (‚Äògift‚Äô) in German ~ label (‚Äòpoison‚Äô) in English</p>

<p>Relating this back to using numbers as labels (write #s below):
label [2 0.5] (‚Äògift‚Äô) in German != label [2 0.5] (‚Äògift‚Äô) in English
label [2 0.5] (‚Äògift‚Äô) in German ~ label [? ?] (‚Äòpoison‚Äô) in English</p>

<p>Now if the English speaker tells the German speaker that they‚Äôre giving them a ‚Äògift‚Äô, the German speaker must translate this to a German translation* that makes them understand that it‚Äôs [gift pic].</p>
<ul>
  <li>not necessarily a word, but possibly a German sentence, or even a paragraph or textbook</li>
</ul>

<p>[show coordinate space w/ Geschenk]</p>

<p>[2 0.5] (Gift, German) != [2 0.5] (Gift, English)
[2 0.5] (Gift, German) ~= [-4 1] (Disgust, English)
[1/3 5/3] (Geschenk, German) ~= [2 0.5] (Gift, English)</p>

<p>Note that there is a difference between ‚Äúwhat gift translates to‚Äù and ‚Äúwhat gift means‚Äù. ‚ÄúWhat gift translates to in German‚Äù means what the label on [gift pic] is in English. ‚ÄúWhat gift means in German‚Äù is about what the LABEL ‚Äògift‚Äô itself points to in German. The entity [gift pic] and the label ‚Äògift‚Äô are not the same. They are only the same when using English, which is defined by the ‚ÄúEnglish basis vectors‚Äù. More about what this means will be discussed in section X, which views basis vectors in a similar way to the Rosetta Stone.</p>

<p>‚Äúwhat gift translates to‚Äù : [gift pic]
‚Äúwhat gift means‚Äù: the label ‚Äògift‚Äô (each label should be highlighted w/ diff font)</p>

<p>But what does the label ‚Äòdisgust‚Äô mean in German? As we see in the German coordinate space, it does not point to any entity. In fact, the label ‚Äòdisgust‚Äô does not mean anything in German. Not all labels have to point to an entity; so in some coordinate spaces, they just mean nonsense. This is an instance of ‚Äònot confusing the map for the territory‚Äô- the map of Switzerland is not 1-1 with Switzerland itself. The model may not capture everything about reality.</p>

<p>[show a place in Switzerland not on the map]</p>

<ul>
  <li>this is an example of a False Friend. link</li>
</ul>

<p>¬´&lt;
Now that we understand the difference between entities and labels, let‚Äôs look back at our example with cats and rats. Remember that in Model 2, the vector I no longer labels the entity [cat pic]; in Model 2, it‚Äôs the vector O that labels [cat pic].</p>

<p>[put vector O on coord sys]</p>

<p>How do we calculate what the new label for [cat] is? As we‚Äôll soon see in section X, the answer is found using Matrix-Vector Multiplication.</p>

<p>¬´&lt;
MOVE TO 1.1+:
Note that the relationships between the entities doesn‚Äôt change. Since the basis vectors from Model 1 still exist in Model 2, you can still use the instructions from Model 1, but you have to translate them using the change of basis matrix.
‚Ä¶ As we‚Äôll see in section X, this is why the dot product instructions work.</p>

<p>section Y will delve deeper into the relationships between concepts, and how they can be preserved or destroyed via matrix multiplication. It retrieves insights that are crucial for‚Ä¶</p>

<p>While [cat pic entity] is a representation of a entity that exists in the real world, 
Relationships are preserved. Analogy. Structure preserving map
[Maps between 2 domains: the real world, and the coordinate space]</p>

:ET